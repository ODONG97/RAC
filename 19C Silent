# Oracle RAC 19c Silent Install GUide

# Requirement
-> git Requirement 문서 참고

# Tuning Linux System Environment(all cluster nodes)

1) /etc/hosts
## Real IP
172.40.40.71 re-ip1
172.40.40.72 re-ip2

## Public IP : Public IP는 DHCP 사용 시 동적으로 할당 되거나 DNS 또는 /etc/hosts 파일에서 정적으로 정의 = 사용자가 접속하기 위한 IP
70.70.70.70 oh1
70.70.70.71 oh2

## Private IP : Clusterware가 node간 통신을 위해 전용으로 사용하는 Interface
10.10.10.12 oh1-priv
10.10.10.13 oh2-priv

## VIP : Virtual ip는 public network 대역에 vip를 할당하여 client가 실제로 vip로 접속을 하게 됨, 빠른 CTF(connection time failover)지원
70.70.70.72 oh1-vip
70.70.70.73 oh2-vip

## SCAN IP : 11gR2 New Feature, client가 하나의 이름으로 db에 접속 가능 하도록 함. scan 이름에 대한 client 요청은 모든 node에서 처리 가능
70.70.70.74 oh-scan
70.70.70.75 oh-scan
70.70.70.76 oh-scan

## DNS SERVER
172.40.40.70 on-dns

2) /etc/sysctl.conf - OS Kernel 매개 변수 최소 권장 값
semmsl(250) semmns(32000) semopm(100) semmni(128)  - /proc/sys/kernel/sem
shmall(Greater than or equal to the value of shmmax, in pages) - /proc/sys/kernel/shmall
ㄴ 시스템이 공유 메모리로 사용 할 수있는 byte를 page size 로 나눈 값
ㄴ echo "`free -k |grep Mem |awk '{print $2}'` /`getconf PAGE_SIZE` * 1024" | bc
shmmax(Half the size of physical memory in bytes) - /proc/sys/kernel/shmmax
ㄴ 시스템이 공유 메모리로 사용 할 수 있는 byte 값
ㄴecho "`free -k |grep Mem |awk '{print $2}'` /2 * 1024" | bc
shmmni(4096) - /proc/sys/kernel/shmmni
panic_on_oops(1) - /proc/sys/kernel/panic_on_oops
file-max(6815744) - /proc/sys/fs/file-max
aio-max-nr(1048576) - /proc/sys/fs/aio-max-nr
ip_local_port_range(Minimum:9000 , Maximum:65500) - /proc/sys/net/ipv4/ip_local_port_range
rmem_default(262144) - /proc/sys/net/core/rmem_default
rmem_max(4194304) - /proc/sys/net/core/rmem_max
wmem_default(262144) - /proc/sys/net/core/wmem_default
wmem_max(1048576) - /proc/sys/net/core/wmem_max

3) /etc/pam.d/login
# pam_limits.so : 사용자 로그인 시 리소스를 제한하는 모듈
session required pam_limit.so
Session : 정보를 보안 로그로 전송하는 등 인증 세션의 시작과 종료를 관리
Required : 실패 시 다른 context들이 스택에서 실행된 후 실패 상태 반환
Pam_limits.so : 이 모듈을 사용하여 자워 사용 제한 설정 가능

4) /etc/profile
- 사용자가 로그인 했을 때 적용되는 스크립트를 정의, /etc/profile or .bash_profile 스크립트 내용 실행 
- /etc/profile -> 모든 사용자에게 공통 적용
- .bash_profile -> 해당 사용자에게만 적용 : /home/userid/.bash_profile
- 사용자가 로그인하면 /etc/profile -> /home/userid/.bash_profile 순서로 실행

if [ $USER = "oracle" ] || [ $USER = "grid" ]; then
if [ $SHELL = "/bin/ksh" ]; then
 ulimit -p 16384
 ulimit -n 65536
else
 ulimit -u 16384 -n 65536
fi
 umask 022
fi

========
Ulimit Option
-a : 모든 제한 사항 보여줌
-c : Maximum Core File Size
-d : Process data segment 최대 크기
-f : shell에 의해 만들어질 수 있는 파일의 최대 크기
-s : 최대 stack 크기
-p : 파이프 크기
-n : open 할 수 있는 파일의 최대 수
-u : 단일 유저가 사용 가능한 process의 최대 개수
-v : 최대 가상 메모리의 양
-S : soft 한도 초과하면 경고 메시지
-H : hard 한도 넘을 수 없음
=========
Ulimit은 process의 자원 한도를 설정하는 명령어, soft 한도 / hard 한도 두 가지로 구분 됨
- soft : 새로운 프로그램을 생성하면 기본적으로 적용되는 한도
- hard : soft 한도에서 최대로 늘릴 수 있는 한도

5) /etc/security/limits.conf - grid user에도 동일 설정
oracle   soft    nproc    16384 (as per unpublished Bug 15971421)
oracle   hard   nproc   16384
oracle   soft    nofile    1024
oracle   hard   nofile    65536
oracle   soft    stack    10240
oracle   hard   stack    10240

6) Avahi Daemon Disable : 로컬에서 IP를 할당 받지 못하면 데몬이 로컬에 알려진 네트워크를 찾아서 자동으로 Hostname과 Domain Name을 할당 받는다.
- DHCP 환경이 없는 네트워크인 wireless 환경에서 수동 설정 없이 자동으로 네트워킹을 할 수 있는 환경 제작
- zeroconf service (리눅스-Avahi , 애플-Bonjour, MS-UPNP) => avahi daemon 활성 시 CSSD Startup이 실패 할 경우가 있기 때문에 Stop&Disable 설정
# Avahi Daemon 비 활성화
systemctl stop avahi-daemon.service
systemctl disable avahi-daemon.service
systemctl status avahi-daemon.service

7) Firewall Daemon Disable : 방화벽 해제 -> 원활한 grid 및 node 간 통신을 위해
systemctl stop firewalld.service
systemctl disable firewalld.service
systemctl status firewalld.service

8) SELinux Disable -> Security Enhanced Linux -> Service나 File 접근에 대한 보안을 위한 리눅스 모듈
vi /etc/selinux/config
SELINUX=disabled => SELinux 비 활성화
reboot => rebooting 후 적용

9) Group 생성 / User 생성 / 권한 부여
[Create OS Groups]
groupadd oinstall
groupadd dba
groupadd asmadmin
groupadd asmdba
groupadd asmoper

[Grid / Oracle Software를 소유하는 User 생성]
useradd -g oinstall -G asmadmin,asmdba,asmoper grid
useradd -g oinstall -G dba,asmdba oracle

[Grid / Oracle User Password 설정]
passwd grid
passwd oracle

[Grid / Oracle 설치하기 위한 디렉토리 생성]
mkdir -p /grid/base
mkdir -p /grid/oraInventory
mkdir -p /grid/product/19c
mkdir -p /oracle/product/19c

[디렉토리 owner 설정 / 권한 부여]
chown -R grid:oinstall /grid
chown -R oracle:oinstall /oracle
chmod -R 775 /grid
chmod -R 775 /oracle
=========================================
ASM Configure(on MasterNode)
1) Storage Type
1. File System : 파일과 그 안에 든 데이터를 저장하고 찾기 쉽도록 유지 및 관리하는 방법
ㄴ 장점 : 디렉토리 구조로 관리하여 사용자의 편의성이 좋음
ㄴ 단점 : OS의 의존도가 너무 높아서 OS 성능에 따라 oracle 성능이 결정 됨 Oracle -> OS File System -> (Shared) Disk

2) Raw Device : OS를 거치지 않고 Oracle이 직접 Disk에 접근하여 I/O 
ㄴ 장점 : Direct로 Disk에 접근하여 속도나 성능 면에서 F/S 보다 좋음
ㄴ 단점 : 파일 1개에 Disk 1개로 Mapping 되어 관리 어려움 Oracle -> (Shared) Disk

3) ASM : Oracle 10gR1 New Feature로 자동 저장 영역 관리 수행, File System의 데이터를 저장하거나 불러오는 원리와 Raw Device 처럼 OS에 거치지 않는 차이가 있음(ASM 요청)
ㄴ 장점 : 자동 Rebalancing 수행하여 disk 추가/삭제 용이하여 효과적인 Disk 관리 / 서로 다른 Disk에 균등하고 자동으로 분산 가능 / F.S에 비해 속도 빠름
ㄴ 단점 : 백업 시 RMAN 사용

[ASM Instance]
ASM Instance는 Oracle이 데이터파일을 I/O하기 위해서 ASM Instance(OS)를 경유하지 않고 ASM Disk에 직접 Write
ASM Instance는 Disk의 extent같은 meta 정보를 제공해주는 역할 수행

[ASMLib]
ASMLib는 ASM을 지원하는 Library이며 ASM Driver를 관리하는 Tool
ASM Driver는 시스템을 다시 시작 할 때마다 ASM과 같이 사용하는 Disk를 Rebind 할 필요가 없어 Disk 장치 구성 및 관리 단순화. (rebind->ASM과 block device 묶어주는 개념)
- oracleasmlib : ASM을 사용하기 위한 Oracle 사용자 library
- oracleasm-support : ASM Library 관리 Utility
- kmod-oracleasm : ASM Library를 위한 Kernel 모듈

=====
configure : ASM Driver 설정 
init / exit : ASM Driver 로드(Start) / Stop
scandisks : Load 된 ASM Disk들을 scan
status : ASM Driver 상태 조회
listdisks : scan 된 ASM Disk 들의 목록을 보여줌
listiids / deleteiids : iid 파일들의 목록을 보여줌 / 삭제
querydisk : ASM Disk가 가리키는 기본 물리적 장치를 식별
createdisk / deletedisk : ASM을 사용하기 위한 device 할당 / 제거
renamedisk : ASM Disk 라벨 이름 변경
update-driver : 최신 ASM Driver를 download
=====
[ASMLib - Partitioning]
PV - VG - LV
/dev/sdb1 - DATA - DATA01, DATA02 // /dev/sdb2 - OCR - OCR01,OCR02,OCR03 // /dev/sdb3 - RECO - RECO01  // /dev/sdb4-GIMR-GIMR01
======
<양 쪽 node에서 수행>
oracleasm rpm install
# rpm -ivh kmod-oracleas.x86_64 0:2.0.8-21.el7
# rpm -ivh oracleasmlib-2.0.12-1.el7.x86_64.rpm
# rpm -ivh oracleasm-support-2.1.11-2.el7.x86_64.rpm

<1번 node에서 수행>
파티션 분할
# fdisk /dev/sdb1~4

PV(Physical volume) 생성
pvcreate /dev/sdb1
pvcreate /dev/sdb2
pvcreate /dev/sdb3
pvcreate /dev/sdb4

VG(Volume Group) 생성
vgcreate DATA /dev/sdb1
vgcreate OCR /dev/sdb2
vgcreate RECO /dev/sdb3
vgcreate GIMR /dev/sdb4

LV(Logical Volume) 생성
lvcreate -L 40g -n DATA01 DATA
lvcreate -L 40g -n DATA02 DATA
lvcreate -L 15g -n OCR01 OCR
lvcreate -L 15g -n OCR02 OCR
lvcreate -L 15g -n OCR03 OCR
lvcreate -L 40g -n RECO01 RECO
lvcreate -L 40g -n RECO02 RECO
lvcreate -L 50g -n GIMR01 GIMR
lvscan ( Logical Volume 확인 )


oracleasm configure -i : # oracleasm configure
Default user to own the driver interface : grid
Default group to own the driver interface : asmadmin
Start Oracle ASM library driver on boot : y
Scan for Oracle ASM disks on boot : y
Writing Oracle ASM library driver configuration : done

oracleasm load : oracleasm init
oracleasm createdisk
oracleasm create DATA01 /dev/DATA/DATA01
... ocr
... reco
... gimr

oracleasm scandisk : # oracleasm scandisks
oracleasm listdisk : # oracleasm listdisks

<2번 노드에서 수행>
시스템 reboot 없이 현재 사용중인 Partition 인식 : # partprobe
oracleasm configure : # oracleasm configure -i
Default user to own the driver interface : grid
Default group to own the driver interface : asmadmin
Start Oracle ASM library driver on boot : y
Scan for Oracle ASM disks on boot : y
Writing Oracle ASM library driver configuration : done

oracleasm load : # oracleasm init
oracleasm scandisk : # oracleasm scandisks
oracleasm listdisk : # oracleasm listdisks

=================================
Grid Silent Installation - Media Unzip & cvuqdisk rpm install
<1번 노드에서 수행>
su - grid
cd /oramedia
unzip -q LINUX.X64_193000_grid_home.zip -d /grid/product/19c
unzip -q LINUX.X64_193000_db_home.zip -d /oracle/product/19c

CVUQDisk rpm install
# cd /grid/product/19c/cv/rpm
# rpm -ivh cvuqdisk-1.0.10-1.rpm
# scp cvuqdisk-1.0.10-1.rpm 172.40.40.72:/home/grid/
# cd /home/grid/
# rpm -ivh cvuqdisk-1.0.10-1.rpm
-> Cluster 검증 유틸리티를 사용하려면 cvuqdisk rpm을 설치
-> cvuqdisk가 없으면 cluster 검증 유틸리티가 공유 디스크를 감지 할 수 없으며, 유틸리티 실행 시 Package cvuqdisk not installed 발생
-> GRID_HOME/cv/rpm 에 위치
-> cvuqdisk를 소유한 그룹을 가리키도록 해야하는데 기본적으로 oinstall을 가리켜 oinstall 그룹이 없다면 export CVUQDISK_GRP=oinstall 혹은 지정하고 싶은 그룹 명시
=======

=======
GRID 환경 변수 설정(node1 & node2)
<<Grid>>
su - grid
vi .bash_profile

export ORACLE_BASE=/grid/base
export ORACLE_HOME=/grid/product/19c
export ORACLE_SID=+ASM1   # +ASM2
export PATH=$ORACLE_HOME/bin:$ORACLE_HOME/OPatch:$PATH
. .bash_profile

<<Oracle>>
su - oracle
vi .bash_profile

export ORACLE_SID= rac1 #rac2
export ORACLE_BASE=/oracle
export ORACLE_HOME=/oracle/product/19c
export PATH=$ORACLE_HOME/bin:$ORACLE_HOME/OPatch:$PATH
. .bash_profile

-> ORACLE_BASE : Trace file 및 Datafile을 저장하는 디렉토리 이름을 기록
   ORACLE_HOME : 설치 하고자 하는 oracle database server를 저장할 디렉토리 이름을 기록
   ORACLE_SID : Oracle Instance를 식별하기 위한 값 (System Identifier)
   PATH : 실행 할 수 있는 binary 파일들의 경로를 명시
   * trace file : DBMS 내부 이벤트 정보, Application의 SQL, 대기 이벤트, 성능 관련 정보 파악 가능
==========
   
==========
SSH UserSetup
<<Grid>>
su - grid
cd /grid/product/19c/oui/prov/resources/scripts
   
./sshUserSetup.sh -hosts "rac1 rac2" -user grid -advanced
./sshUserSetup.sh -hosts "rac1 rac2" -user oracle -advanced
if error -> ./sshUserSetup.sh -user grid -hosts "rac1 rac2" -noPromptPassphrase -advanced

1번 노드 => 2번 노드로 비밀번호 응답하지 않는지 체크
hosts : 공백으로 구분되게 원격 host를 명시
user : 원격 host에 해당 user를 명시
advanced : 원격 host간 ssh 연결이 설정되며 원격 host간 파일 복사 가능
noPromptPassphrase : 원격을 붙을 때 Password 묻지 않음
==========
Run the following cluster verify command(runcluvfy.sh) -> error 확인
<<Grid>>
su - grid
cd /grid/product/19c
./runcluvfy.sh stage -pre crsinst -n rac1,rac2 -verbose > result.out

PRVG-1172 : Grid 설치 할 때 제대로 설정 되지 않은 네트워크가 있어서 발생되는 error -> Virtual network(virbr0)는 guest os user들이 network service에 접근하는 것을 허락하기 위한
            인터페이스, 가상화를 지원하기 위함
[ Solution ]
가상화 서비스 및 가상 장치를 관리하는 virbr0 인터페이스를 사용하지 않기에 ignore 진행

resolv.conf Integrity ....FAILED : DNS를 활용한 name server를 사용하지 않아 resolv.conf를 check 할 때 발생하는 error
[ Solution ] : 기본적으로 host 정보를 읽을 때 /etc/resolv.conf를 읽고 정보가 없으면 /etc/hosts를 읽는데 설정 해주었기 때문에 ignore

PRVG-11250 : 일부 CVU check는 시스템에서 필요한 정보를 검색 할 수 있는 root 권한이 필요한데 root 자격 증명을 할 수 없는 경우 "root 사용자 권한이 필요하기 때문에 수행되지 않았습니다"
라는 메세지가 나옴
[ Solution ] : runcluvfy 실행 시 -method root 옵션을 사용하여 root 비밀번호를 입력하여 수행할 수 있음
               ./runcluvfy.sh stage -pre crsinst -n rac1,rac2 -verbose -method root -> Enter "Root"password
               
PRVE-0421 : cluvfy 검사가 file system의 실제 mount를 검사하지 않지만 /etc/fstab에서 mount의 행(/dev/shm)을 찾는 경우 발생하는 버그 (Doc id 2065603.1)
[ Solution ] : 실제로 /dev/shm 이 mount가 되어 있기 때문에 ignore
==========
su - grid
ls $ORACLE_HOME/install/response gridsetup.rps-> response file을 수정하여 grid 설치 가능
그럼 vi grid.rsp 를 만들어주어야 하는가?
